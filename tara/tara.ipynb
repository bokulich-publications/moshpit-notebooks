{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TARA Oceans data analysis\n",
    "This notebook contains the analysis of the samples fetched for the BioProject PRJEB1787. This BioProject comprises approx. 240 samples corresponding to the bacterial fraction of the collected sea water. All the samples were subject to taxonomic classification using Kraken 2 through the `classify-kraken2` action from the q2-moshpit QIIME 2 plugin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import qiime2 as q2\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import matplotlib as mp\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from qiime2.plugins import taxa, emperor\n",
    "from skbio import OrdinationResults\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_abundances(\n",
    "    df: pd.DataFrame, \n",
    "    ax, \n",
    "    labels: Dict,\n",
    "    coord: Tuple,\n",
    "    color_map: Dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a horizontal stacked bar chart of feature abundances from a DataFrame.\n",
    "\n",
    "    The function sorts features by their abundance in the first sample, assigns colors based on those abundances \n",
    "    using the provided color map, and creates a bar plot. The y-axis labels are updated to show depth information,\n",
    "    and the chart includes a title displaying the coordinates of the sampled location. The y-axis is inverted to \n",
    "    present the data in a more intuitive order.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): A DataFrame where each column represents a different feature and each row represents \n",
    "                             a different sample. The first row is used to sort features by abundance.\n",
    "        - ax (matplotlib.axes.Axes): The axes onto which the plot will be drawn.\n",
    "        - labels (dict): A dictionary mapping original y-axis labels to descriptive labels that indicate depth.\n",
    "        - coord (tuple): A tuple containing latitude and longitude coordinates of the sample location (lat, lon).\n",
    "        - color_map (dict): A dictionary mapping feature names to their corresponding colors.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort features (columns) by abundance in the first sample\n",
    "    sorted_features = df.iloc[0].sort_values(ascending=False).index\n",
    "    df = df[sorted_features]\n",
    "\n",
    "    # Assign colors to features: top features use one color map, others use another\n",
    "    feature_colors = [color_map[feature] for feature in df.columns]\n",
    "\n",
    "    # Plot the DataFrame with the assigned colors\n",
    "    df.plot(kind='barh', stacked=True, ax=ax, color=feature_colors)\n",
    "    \n",
    "    # Update y-axis labels with depth information\n",
    "    new_labels = [labels[x.get_text()] for x in ax.get_yticklabels()]\n",
    "    ax.set_yticklabels(new_labels)\n",
    "    ax.set_ylabel(\"Depth\")\n",
    "    ax.set_title(f\"Location: lat={coord[0]}, lon={coord[1]}\")\n",
    "    ax.legend().set_visible(False)\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "\n",
    "metadata_fp = os.path.join(data_dir, \"metadata.tsv\")\n",
    "metadata = pd.read_csv(metadata_fp, sep=\"\\t\", index_col=0)\n",
    "\n",
    "bracken_shannon_fp = os.path.join(data_dir, \"shannon_vector.qza\")\n",
    "bracken_df = q2.Artifact.load(bracken_shannon_fp).view(pd.Series)\n",
    "\n",
    "pcoa_fp = os.path.join(data_dir, \"bray_curtis_pcoa_results.qza\")\n",
    "pcoa = q2.Artifact.load(pcoa_fp)\n",
    "\n",
    "ft = q2.Artifact.load(os.path.join(data_dir, \"bracken_ft_rarefied.qza\"))\n",
    "taxonomy = q2.Artifact.load(os.path.join(data_dir, \"bracken_taxonomy.qza\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "In this section we will clean up the metadata and merge it with the Shannon diversity results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the \"5-160\" combined depths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata[metadata[\"Depth\"] != '5-160']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert depth to numeric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"Depth\"] = pd.to_numeric(metadata[\"Depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new column for geocoordinates. For easier plotting, we will round the coordinates to the second decimal place and assume that whatever samples were taken within that range originate from the same spot on Earth. Since we have \"start\" and \"end\" coordinate for both, latitude and longitude, we will take the average of both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace lat/lon that are out of range with NaN\n",
    "for col in [\"Latitude_Start\", \"Latitude_End\", \"Longitude_Start\", \"Longitude_End\"]:\n",
    "    metadata.loc[(metadata[col] < -180) | (metadata[col] > 180), col] = np.nan\n",
    "\n",
    "# remove coordinates which do not match between _start and _end (one is negative, the other positive)\n",
    "for (col_start, col_end) in [(\"Latitude_Start\", \"Latitude_End\"), (\"Longitude_Start\", \"Longitude_End\")]:\n",
    "    selection = ((metadata[col_start] < 0) & (metadata[col_end] > 0) | (metadata[col_start] > 0) & (metadata[col_end] < 0))\n",
    "    metadata.loc[selection, [col_start, col_end]] = np.nan\n",
    "\n",
    "# add lat/lon columns by averaging the values from *_Start and *_End columns\n",
    "metadata[\"Lat\"] = round((metadata[\"Latitude_Start\"] + metadata[\"Latitude_End\"]) / 2, 2)\n",
    "metadata[\"Lon\"] = round((metadata[\"Longitude_Start\"] + metadata[\"Longitude_End\"]) / 2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add additional columns for the rounded coordinates to allow grouping samples that are located nearby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[\"Lat1\"] = round(metadata[\"Lat\"], 1)\n",
    "metadata[\"Lon1\"] = round(metadata[\"Lon\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the diversity metrics with the metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracken_df = bracken_df.to_frame().merge(metadata, left_index=True, right_index=True)\n",
    "pcoa_df = pcoa.view(OrdinationResults).samples.merge(bracken_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find \"duplicated\" samples which we will treat as replicates. We assume that whatever was collected at the same geo-location and depth is a replicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated = bracken_df.duplicated([\"Longitude_Start\", \"Latitude_Start\", \"Depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracken_df[duplicated].sort_values(\n",
    "    [\"Longitude_Start\", \"Longitude_End\", \"Latitude_Start\", \"Latitude_End\", \"Depth\"], inplace=False\n",
    ").loc[:, [\"Longitude_Start\", \"Longitude_End\", \"Latitude_Start\", \"Latitude_End\", \"Depth\", \"Bytes\", \"shannon_entropy\", \"temperature\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De-duplicate the table by calculating the average diversity from all replicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracken_df_dedupl = bracken_df.groupby([\"Lat\", \"Lon\", \"Depth\"])[\"shannon_entropy\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracken_df_dedupl = bracken_df_dedupl.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize depths based on quantiles for easier plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_quantiles = bracken_df_dedupl[\"Depth\"].quantile([0.4, 0.45,  0.5, 0.6, 0.7, 0.8, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = []\n",
    "for i, q in enumerate(depth_quantiles):\n",
    "    start = round(depth_quantiles.iloc[i], 0)\n",
    "    if i < len(depth_quantiles) - 1:\n",
    "        end = round(depth_quantiles.iloc[i + 1], 0)\n",
    "    else:\n",
    "        end = float('inf')\n",
    "\n",
    "    depth = f'{start}-{end}'\n",
    "    condition1 = (start <= bracken_df_dedupl['Depth']) & (bracken_df_dedupl['Depth'] < end)\n",
    "    condition2 = (start <= bracken_df['Depth']) & (bracken_df['Depth'] < end)\n",
    "    \n",
    "    bracken_df_dedupl.loc[condition1, 'Depth_category'] = depth\n",
    "    bracken_df.loc[condition2, 'Depth_category'] = depth \n",
    "    \n",
    "    slices.append((start, end))\n",
    "\n",
    "bracken_df_dedupl.groupby(\"Depth_category\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bray-Curtis PCoA\n",
    "We will plot the first two dimensions of the Bray-Curtis PCoA analysis to see how the samples cluster depending on the sampling depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"Depth\"\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "color_count = pcoa_df[category].nunique()\n",
    "base_color = sns.husl_palette(6, h=0.5)[1]\n",
    "colormap = LinearSegmentedColormap.from_list(\"custom_cmap\", [\"white\", base_color])\n",
    "\n",
    "# Calculate the actual min and max of the depth values\n",
    "min_depth = pcoa_df[category].min()\n",
    "max_depth = pcoa_df[category].max()\n",
    "\n",
    "# Calculate the color range for the colormap\n",
    "lower_threshold = 0.2\n",
    "upper_threshold = 1.0\n",
    "\n",
    "colors = [\n",
    "    colormap(i) for i in \n",
    "    np.linspace(lower_threshold, upper_threshold, color_count)\n",
    "]\n",
    "\n",
    "colors_map = {\n",
    "    depth: color for depth, color in\n",
    "    zip(pcoa_df[category].value_counts().sort_index().index, colors)\n",
    "}\n",
    "\n",
    "pcoa_df[\"Colors\"] = pcoa_df[category].map(colors_map)\n",
    "pcoa_df.sort_values(category, inplace=True, ascending=False)\n",
    "\n",
    "# Create scatter plot\n",
    "sns.scatterplot(\n",
    "    data=pcoa_df, x=0, y=1, color=pcoa_df[\"Colors\"], s=50, alpha=0.5, ax=ax1\n",
    ")\n",
    "\n",
    "# Create a color bar instead of a legend\n",
    "norm = plt.Normalize(min_depth, max_depth)\n",
    "sm = plt.cm.ScalarMappable(cmap=colormap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "# Create a color bar\n",
    "cbar = fig1.colorbar(\n",
    "    sm, ax=ax1, orientation='vertical', fraction=0.045, pad=0.01\n",
    ")\n",
    "cbar.ax.invert_yaxis()\n",
    "cbar.set_label(category)\n",
    "\n",
    "# Define ticks as per actual depth values\n",
    "tick_interval = 200\n",
    "ticks = np.arange(\n",
    "    int(min_depth // tick_interval) * tick_interval,\n",
    "    int(max_depth // tick_interval + 1) * tick_interval,\n",
    "    tick_interval\n",
    ")\n",
    "\n",
    "cbar.set_ticks(ticks)\n",
    "cbar.set_ticklabels(ticks)\n",
    "\n",
    "# Set axes labels and title\n",
    "ax1.set_xlabel(\"PCoA 1\")\n",
    "ax1.set_ylabel(\"PCoA 2\")\n",
    "ax1.set_title(\"Bray-Curtis\")\n",
    "\n",
    "# Set equal aspect ratio for square plot\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1.savefig(os.path.join(data_dir, \"figure1.svg\"), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global diversity overview\n",
    "Here we will look how the Shannon diversity correlates with the sample location and depth. Moreover, we will look at the abundances of the taxa at four different locations change with the sampling depth.\n",
    "\n",
    "Let's use the `Lat1`/`Lon1` rounded coordinates to count how many samples per location there are. We will then select 4 locations with the highest counts of samples to analyse their per-depth abundances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcoa_df.groupby([\"Lat1\", \"Lon1\"]).count().sort_values(\"Depth\")[\"Depth\"].tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need samples with at least 3 different depths - let's visually check that some of the coordinates above can provide us with those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = [(-35.2, 26.3), (-9.0, -139.2), (-31.0, 4.7), (-30.2, -43.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (lat, lon) in coordinates:\n",
    "    print(f\"Lat: {lat}, Lon: {lon}\")\n",
    "    print(pcoa_df.loc[(pcoa_df[\"Lat1\"] == lat) & (pcoa_df[\"Lon1\"] == lon), \"Depth\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = mp.colormaps['Blues']\n",
    "lower_threshold = 0.2\n",
    "upper_threshold = 1.0\n",
    "colors = [\n",
    "    mcolors.rgb2hex(colormap(lower_threshold + (upper_threshold - lower_threshold) * (i / len(slices))))\n",
    "    for i in range(len(slices))\n",
    "]\n",
    "\n",
    "scale = 0.15\n",
    "fig2 = go.Figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bracken_df_dedupl['text'] = \"Shannon diversity: \" + bracken_df_dedupl['shannon_entropy'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot all the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(slices)):\n",
    "    lim = slices[i]\n",
    "    df_sub = bracken_df_dedupl[\n",
    "        (lim[0] <= bracken_df_dedupl[\"Depth\"]) & (bracken_df_dedupl[\"Depth\"] < lim[1])\n",
    "    ]\n",
    "    fig2.add_trace(\n",
    "        go.Scattergeo(\n",
    "            locationmode='ISO-3',\n",
    "            lon=df_sub['Lon'],\n",
    "            lat=df_sub['Lat'],\n",
    "            text=df_sub['text'],\n",
    "            marker=dict(\n",
    "                size=df_sub['shannon_entropy'] ** 2 / scale,\n",
    "                color=colors[i],\n",
    "                sizemode='area'\n",
    "            ),\n",
    "            name = '{0} - {1}'.format(lim[0], lim[1])\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new points indicating the four locations which we will be analysing in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lat, lon in coordinates:\n",
    "    fig2.add_trace(\n",
    "        go.Scattergeo(\n",
    "            locationmode='ISO-3',\n",
    "            lon=[lon],\n",
    "            lat=[lat],\n",
    "            text=[f\"Location: lat={lat}, lon={lon}\"],\n",
    "            marker=dict(\n",
    "                size=25,\n",
    "                color=\"red\",\n",
    "                sizemode='area'\n",
    "            ),\n",
    "            name = f\"Location: lat={lat}, lon={lon}\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2.update_layout(\n",
    "    width=1200,\n",
    "    height=650,\n",
    "    showlegend=True,\n",
    "    geo=dict(\n",
    "        scope='world',\n",
    "        landcolor='rgb(217, 217, 217)',\n",
    "    ),\n",
    "    legend=dict(\n",
    "        yanchor=\"bottom\", y=0.075,\n",
    "        xanchor=\"left\", x=0.75\n",
    "    ),\n",
    "    margin=dict(t=0)\n",
    ")\n",
    "\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig2, os.path.join(data_dir, 'figure2.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abundance analysis per location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collapse the table to the `order` level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 4\n",
    "\n",
    "ft_collapsed, = taxa.methods.collapse(\n",
    "    table=ft,\n",
    "    taxonomy=taxonomy,\n",
    "    level=level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we convert the artifacts to Pandas' objects and normalize the feature table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df = ft_collapsed.view(pd.DataFrame)\n",
    "taxonomy_ser = taxonomy.view(pd.Series)\n",
    "\n",
    "ft_df = ft_df.div(ft_df.sum(axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will collect all the _unique_ features across all the plots and find the top N features with highest abunndances: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_features = 5\n",
    "top_features = []\n",
    "other_features = []\n",
    "for (lat, lon) in coordinates:\n",
    "    metadata_sorted = metadata.sort_values([\"Depth\", \"Lat1\", \"Lon1\"], ascending=True, inplace=False)\n",
    "    samples = metadata_sorted.loc[\n",
    "        (metadata_sorted[\"Lat1\"] == lat) & (metadata_sorted[\"Lon1\"] == lon), [\"Lat1\", \"Lon1\", \"Depth\"]\n",
    "    ].reset_index().groupby(\"Depth\").first()[\"ID\"].tolist()\n",
    "    df = ft_df.loc[samples, :]\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    df = df.sort_values(by=df.index[0], axis=1, ascending=False)\n",
    "    \n",
    "    for i, feature in enumerate(df.columns):\n",
    "        if i < num_top_features and feature not in top_features:\n",
    "            top_features.append(feature)\n",
    "        else:\n",
    "            other_features.append(feature)\n",
    "all_features = set(top_features + other_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two color maps: one for the top N features and the other one for all the remaining ones: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_color_list = sns.husl_palette(len(top_features), h=.5)\n",
    "other_color_list = mp.colormaps['Greys'](np.linspace(0.2, 1.8, len(all_features) - len(top_features)))\n",
    "\n",
    "color_map = {}\n",
    "top_feature_count = 0\n",
    "other_feature_count = 0\n",
    "for feature in [*top_features, *other_features]:\n",
    "    if feature in top_features and feature not in color_map:\n",
    "        color_map[feature] = top_color_list[top_feature_count]\n",
    "        top_feature_count += 1\n",
    "    elif feature not in top_features and feature not in color_map:\n",
    "        color_map[feature] = other_color_list[other_feature_count % len(other_color_list)]\n",
    "        other_feature_count += 1\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3, axes3 = plt.subplots(4, 1, figsize=(5, 8))\n",
    "top_handles = []\n",
    "top_labels = []\n",
    "\n",
    "# Plot each subplot with the unified color map\n",
    "metadata_sorted = metadata.sort_values([\"Depth\", \"Lat1\", \"Lon1\"], ascending=True, inplace=False)\n",
    "for (lat, lon), ax in zip(coordinates, axes3):\n",
    "    # Find sample IDs\n",
    "    samples = metadata_sorted.loc[\n",
    "        (metadata_sorted[\"Lat1\"] == lat) & (metadata_sorted[\"Lon1\"] == lon), [\"Lat1\", \"Lon1\", \"Depth\"]\n",
    "    ].reset_index().groupby(\"Depth\").first()[\"ID\"].tolist()\n",
    "    labels = dict(metadata_sorted.loc[samples, \"Depth\"])\n",
    "\n",
    "    # Slice feature table\n",
    "    df = ft_df.loc[samples, :]\n",
    "\n",
    "    # Remove columns (features) with zeros across all samples\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    \n",
    "    plot_abundances(df, ax, labels, (lat, lon), color_map)\n",
    "\n",
    "    # Collect handles and labels for the top features\n",
    "    handles_legend, labels_legend = ax.get_legend_handles_labels()\n",
    "    for handle, label in zip(handles_legend[:num_top_features], labels_legend[:num_top_features]):\n",
    "        label = label.split(\";\")[-1][3:]\n",
    "        if label not in top_labels:\n",
    "            top_handles.append(handle)\n",
    "            top_labels.append(label)\n",
    "\n",
    "# Add the combined legend for the top features from each subplot\n",
    "fig3.legend(top_handles, top_labels, title='Top Features', loc='center right', bbox_to_anchor=(1.75, 0.5))\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # Adjust layout to make space for the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig3.savefig(os.path.join(data_dir, \"figure3.svg\"), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q2-metagenome-2024.10",
   "language": "python",
   "name": "q2-metagenome-2024.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
